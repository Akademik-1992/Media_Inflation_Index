{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c433b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01863c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка и предобработка\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "# https://github.com/huggingface/transformers\n",
    "# обучение, загрузка по формату библиотеки, оптимизаторы\n",
    "# !pip install transformers\n",
    "# !pip install datasets\n",
    "# !pip install umap-learn\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "# обучение\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "# предобработка и финальный отчет по метрикам\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "# кластеризация\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import umap\n",
    "from sklearn.cluster import DBSCAN\n",
    "# прогресс бар\n",
    "from tqdm import tqdm\n",
    "# очистка кешей\n",
    "import gc\n",
    "# размер шрифта в графиках\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7937d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('C:/Users/Академик/PycharmProjects/News_parsing/Разметка/Разметка GigaChat_Sentiments_14.12.2023.xlsx')\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ef5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da29ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70bc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ed472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_0 = df[df['label'] == 'Негативный'].sample(n=1632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f15107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1 = df[df['label'] == 'Позитивный']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat((df_0, df_1), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34653589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28087916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # меняем названия колонок под huggin face\n",
    "# df.columns = ['description', 'labels']\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# Label_encoder = preprocessing.LabelEncoder()\n",
    "# Label_encoder.fit(df['labels'])\n",
    "# Label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['labels'] = Label_encoder.fit_transform(df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74924fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем\n",
    "# df.to_csv('df_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70051c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('classes.npy', Label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ccf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # перемешиваем и рабиваем на train test\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# train = df[:int(len(df)*0.8)]\n",
    "# test =  df[int(len(df)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3048e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.labels.value_counts(), test.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('train.csv', index=False)\n",
    "# test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ai-forever/ruBert-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# если есть желание дообучить лучшую модель - оставить эту строчку кода, иначе убрать\n",
    "# model_name = 'sber-80(-84)'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, \n",
    "                                                           num_labels=2, \n",
    "                                                           output_attentions=False,\n",
    "                                                           output_hidden_states=False,\n",
    "                                                           ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68541ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(model.named_parameters())\n",
    "names[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ffe6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d310fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378491b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': 'train.csv', 'test': 'test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadcc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda e: tokenizer(e['description'], truncation = True, max_length=300, padding='max_length'), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413566a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# это стандартные колонки для формата пайторча, все кроме них убираем\n",
    "pytorch_style_columns = ['input_ids', 'token_type_ids', 'attention_mask', 'labels']  #\n",
    "# убираем их из загрузчика\n",
    "dataset = dataset.remove_columns(list(set(list(dataset['train'].features.keys())) - set(pytorch_style_columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39477036",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad383623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переврдим в формат пайторча\n",
    "# сразу грузим на gpu, если есть cuda, иначе девайс стоит убрать из аргумента\n",
    "dataset.set_format(type='torch', columns=pytorch_style_columns, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09afe671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# установить 8 или больше, если более 16 гб видеопамяти\n",
    "train_dataloader = DataLoader(dataset['train'], shuffle=True, batch_size=1)\n",
    "test_dataloader = DataLoader(dataset['test'], shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оптимизатор AdamW, лр стоит поперебирать\n",
    "optimizer = AdamW(model.parameters(), lr=2e-6)\n",
    "# количество эпох можно побольше поставить\n",
    "num_epochs = 4\n",
    "# количество шагов\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "# будем линейно увеличивать первые 200 шагов\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"constant_with_warmup\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=2000,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ce730",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee798a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c744f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# лучший f1, по нему будем сохранять\n",
    "best_f1 = 0.\n",
    "# будем отображать каждые 10% эпохи\n",
    "show_train_loss_every_num_epoch = 0.1\n",
    "\n",
    "# проходимся по всем эпохам\n",
    "for epoch in range(num_epochs):\n",
    "    # отображаем номера эпох\n",
    "    print(40*'-', '\\nepoch', epoch+1)\n",
    "    # переводим в режим тренировки\n",
    "    model.train()\n",
    "    # смотрим на средний лосс за 10% эпохи\n",
    "    losses = []\n",
    "    # итерируемся по треин части\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # переводим в режим тренировки\n",
    "        model.train()\n",
    "        # print(batch)\n",
    "        # переносим батч на гпу, где и модель\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        # print(batch)\n",
    "        # получаем прогнозы\n",
    "        outputs = model(**batch)\n",
    "        # print(outputs)\n",
    "        # получаем лосс встроенный вместе с моделью (кросс-энтропия)\n",
    "        loss = outputs.loss\n",
    "        # делаем обратный проход\n",
    "        loss.backward()\n",
    "        # шаг по градиенту\n",
    "        optimizer.step()\n",
    "        # шаг по скорости\n",
    "        lr_scheduler.step()\n",
    "        # шаг по оптимизатору\n",
    "        optimizer.zero_grad()\n",
    "        # фиксируем потери на треин\n",
    "        losses.append(loss.item())\n",
    "        # отображаем каждый 10% эпохи\n",
    "        if i%int(len(train_dataloader)*show_train_loss_every_num_epoch)==int(len(train_dataloader)*show_train_loss_every_num_epoch)-1:\n",
    "            print(f'train loss [{i*100/len(train_dataloader):.2f}%]: {np.array(losses).mean():.3f}')\n",
    "            losses = []\n",
    "            # валидируемся в конце эпохи\n",
    "            print('\\nvalidating')\n",
    "            # загружаем все основные метрики\n",
    "            f1 = load_metric('f1')\n",
    "            acc = load_metric('accuracy')\n",
    "            precision = load_metric('precision')\n",
    "            recall = load_metric('recall')\n",
    "            with torch.no_grad():\n",
    "                # переводим в режим валидации\n",
    "                model.eval()\n",
    "                # проходимся по всем батчам из теста\n",
    "                for batch in tqdm(test_dataloader):\n",
    "                    # переносим их на гпу\n",
    "                    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                    # не обновляя параметры получаем прогнозы\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(**batch)\n",
    "                    # получаем сразу логиты\n",
    "                    logits = outputs.logits\n",
    "                    # находим верный ответ\n",
    "                    predictions = torch.argmax(logits, dim=-1)\n",
    "                    # логируем в метрики по f1\n",
    "                    f1.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "                    acc.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "                    precision.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "                    recall.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "                # находим взвешенные по кол-ву примеров на тест метрики\n",
    "                print('weighted summary:')\n",
    "                print('Test acc:', acc.compute()['accuracy'])\n",
    "                print('Test precision:', precision.compute(average = 'weighted')['precision'])\n",
    "                print('Test recall:', recall.compute(average = 'weighted')['recall'])\n",
    "                f1_weighted = f1.compute(average = 'weighted')['f1']\n",
    "                print('Test f1:', f1_weighted, '\\n')\n",
    "                # если текущая f1 лучше максимальной\n",
    "                if f1_weighted > best_f1:\n",
    "                    # максмальная становится текущей\n",
    "                    best_f1 = f1_weighted\n",
    "                    # сохраняем модель\n",
    "                    model.save_pretrained(f\"ruBert-base_f1_max={round(best_f1, 3)}\")\n",
    "\n",
    "    # переводим обратно в режим тренировки для следующей эпохи\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef737eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('classes.npy', Label_encoder.classes_)\n",
    "Label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# для того, чтобы восстановить кодировку целевых признаков как при обучении\n",
    "Label_encoder.classes_ = np.load('classes.npy', allow_pickle=True)\n",
    "\n",
    "# валидируем по тесту\n",
    "# реальные ответы и предсказания\n",
    "true = []\n",
    "preds = []\n",
    "\n",
    "# переводим модель в режим инференса\n",
    "model.eval()\n",
    "# проходимся по батчам теста\n",
    "for batch in tqdm(test_dataloader):\n",
    "    # переносим батч на GPU\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    # без обновления параметров находим прогнозы\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    # получаем логиты\n",
    "    logits = outputs.logits\n",
    "    # из логитов прогноз\n",
    "    predictions = torch.argmax(logits, dim=-1) #predictions = torch.argmax(logits, dim=-1)\n",
    "#     print(round(float(predictions[0][1]),3))\n",
    "    # добавляем пачки ответов и прогнозов в массивы\n",
    "#     true += batch[\"labels\"].detach().cpu().numpy().tolist()\n",
    "    preds += predictions.detach().cpu().numpy().tolist()\n",
    "#     preds.append(float(predictions[0][1]))\n",
    "\n",
    "# ковертируем ответы и прогнозы обратно в человеко-читаемые названия классов, смотрим report по всем метрикам по каждому классу\n",
    "# print(classification_report(Label_encoder.inverse_transform(true), Label_encoder.inverse_transform(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48135739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_df = pd.DataFrame(preds)\n",
    "# preds_df.to_excel('Тестирование на 3 класса.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (precision_score, recall_score, f1_score, classification_report, \n",
    "                             accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce741beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact = list(test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(fact, preds)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot(cmap='Blues')\n",
    "\n",
    "f1 = f1_score(fact, preds, average='macro')\n",
    "print(f'f1_score = {round(f1, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b3430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно изменить порог принятия решения\n",
    "# final_pred = []\n",
    "# for prob in preds:\n",
    "#     if prob > 0.1:\n",
    "#         answer = 1\n",
    "#     else:\n",
    "#         answer = 0\n",
    "#     final_pred.append(answer)\n",
    "# cm = confusion_matrix(fact, final_pred)\n",
    "# cm_display = ConfusionMatrixDisplay(cm).plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно изменить порог принятия решения\n",
    "# test_different = []\n",
    "# for prob in preds:\n",
    "#     if prob < 0.3:\n",
    "#         test_different.append('Негативный')\n",
    "#     elif prob >0.3 and prob < 0.7:\n",
    "#         test_different.append('Нейтральный')\n",
    "#     else:\n",
    "#         test_different.append('Позитивный')\n",
    "# pd.DataFrame(test_different).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
